# TransAI Phase 2: Intelligent Medical Document Translation System

## ğŸ“‹ Overview

Phase 2 is an advanced medical and clinical document translation system that achieves **98.3% token reduction** (20,473 â†’ 413 tokens per request) while maintaining high translation quality. The system specializes in clinical trial, medical device, and pharmaceutical documentation translation using intelligent context building, efficient caching, and optimized LLM integration.

**Key Capabilities:**
- 98.3% reduction in LLM tokens through smart context optimization
- Clinical trial and medical device translation specialization
- 720 words/minute processing speed (10x faster than human translation)
- Sub-millisecond caching via Valkey/Redis
- 84% average translation quality score
- Support for tag preservation (CAT tool integration)

## ğŸ“‚ Documentation Structure

All documentation is organized into 7 categories. Navigate by category or use the quick links below.

### Documentation Categories

```
docs/
â”œâ”€â”€ 01_getting_started/              â† Start here!
â”‚   â”œâ”€â”€ INDEX.md                     (Read first for navigation)
â”‚   â”œâ”€â”€ SETUP_CHECKLIST.md
â”‚   â””â”€â”€ FILE_ORGANIZATION_GUIDE.md
â”‚
â”œâ”€â”€ 02_architecture/                 â† Understand the system
â”‚   â”œâ”€â”€ INDEX.md
â”‚   â”œâ”€â”€ PHASE2_MVP_ARCHITECTURE.md
â”‚   â”œâ”€â”€ PHASE2_ARCHITECTURE_DIAGRAM.md
â”‚   â””â”€â”€ IMPLEMENTATION_BLUEPRINT.md
â”‚
â”œâ”€â”€ 03_core_features/                â† Learn to use
â”‚   â”œâ”€â”€ INDEX.md
â”‚   â”œâ”€â”€ TRANSLATION_PIPELINE_STEPBYSTEP.md
â”‚   â”œâ”€â”€ VALKEY_INTEGRATION_SUMMARY.md
â”‚   â”œâ”€â”€ TAG_PRESERVATION_IMPLEMENTATION.md
â”‚   â””â”€â”€ TECHNICAL_IMPLEMENTATION.md
â”‚
â”œâ”€â”€ 04_glossary_and_terminology/     â† Manage terms
â”‚   â”œâ”€â”€ INDEX.md
â”‚   â”œâ”€â”€ GLOSSARY_SYSTEM.md
â”‚   â”œâ”€â”€ HOW_TO_ADD_GLOSSARIES.md
â”‚   â””â”€â”€ GLOSSARY_SEARCH_METHODS_ANALYSIS.md
â”‚
â”œâ”€â”€ 05_advanced_topics/              â† Advanced features
â”‚   â”œâ”€â”€ INDEX.md
â”‚   â”œâ”€â”€ TRANSLATION_PATTERNS_FOR_PROMPT.md
â”‚   â”œâ”€â”€ PROTOCOL_PAIRING_FEASIBILITY.md
â”‚   â”œâ”€â”€ PROTOCOL_PAIRS_USAGE_STRATEGY.md
â”‚   â””â”€â”€ TRANSLATION_FEEDBACK_ANALYSIS_AND_RECOMMENDATIONS.md
â”‚
â”œâ”€â”€ 06_performance_and_optimization/ â† Optimize & test
â”‚   â”œâ”€â”€ INDEX.md
â”‚   â”œâ”€â”€ PHASE2_MVP_TEST_PLAN.md
â”‚   â”œâ”€â”€ PHASE2_TEST_KIT_ANALYSIS.md
â”‚   â””â”€â”€ TOKEN_USAGE_ANALYSIS_REPORT.md
â”‚
â””â”€â”€ 07_project_management/           â† Operations & security
    â”œâ”€â”€ INDEX.md
    â”œâ”€â”€ COMPLETION_REPORT.md
    â””â”€â”€ GIT_SECURITY_CHECKLIST.md
```

---

## ğŸ—ºï¸ Quick Navigation

**ğŸ‘¤ New to the project?**
â†’ Start with [01_getting_started/INDEX.md](01_getting_started/INDEX.md)
- Setup checklist
- Project organization
- Initial configuration

**ğŸ—ï¸ Want to understand the system?**
â†’ Go to [02_architecture/INDEX.md](02_architecture/INDEX.md)
- System architecture
- Component diagrams
- Design decisions

**âš™ï¸ Ready to use it?**
â†’ Read [03_core_features/INDEX.md](03_core_features/INDEX.md)
- Translation pipeline
- Caching system
- Tag preservation

**ğŸ“š Need glossary help?**
â†’ See [04_glossary_and_terminology/INDEX.md](04_glossary_and_terminology/INDEX.md)
- How to add glossaries
- Glossary system overview
- Search methods

**ğŸš€ Advanced features?**
â†’ Check [05_advanced_topics/INDEX.md](05_advanced_topics/INDEX.md)
- Translation optimization
- Protocol handling
- Feedback analysis

**âš¡ Performance tuning?**
â†’ Visit [06_performance_and_optimization/INDEX.md](06_performance_and_optimization/INDEX.md)
- Testing strategy
- Token analysis
- Performance metrics

**ğŸ” Operations & security?**
â†’ Go to [07_project_management/INDEX.md](07_project_management/INDEX.md)
- Project status
- Security checklist
- Git workflow

---

## ğŸš€ Quick Start

### Prerequisites

- **Python 3.11+**
- **Valkey or Redis server** (for caching layer)
- **OpenAI API Key** (required for GPT-5 OWL and GPT-4o models)
- **macOS, Linux, or Windows with WSL**

### Installation

```bash
# 1. Navigate to project directory
cd /Users/won.suh/Project/transai

# 2. Create Python virtual environment
python3 -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# 3. Install Python dependencies
pip install -r src/requirements.txt

# 4. Install and start Valkey server
# Option A: macOS with Homebrew
brew install valkey
valkey-server

# Option B: Using Docker (any platform)
docker run -d -p 6379:6379 valkey/valkey

# Option C: Use system Redis (if available)
redis-server

# 5. Configure environment variables
cp src/.env.example src/.env  # Or create src/.env file manually
```

## âš™ï¸ Configuration

### Environment Variables (.env)

Create a `.env` file in the `src/` directory with the following variables:

```bash
# OpenAI Configuration (REQUIRED)
OPENAI_API_KEY=your_openai_api_key_here

# Alternative LLM Providers (Optional - currently not implemented in production)
ANTHROPIC_API_KEY=your_anthropic_api_key_optional
GEMINI_API_KEY=your_gemini_api_key_optional
UPSTAGE_API_KEY=your_upstage_api_key_optional

# Valkey/Redis Configuration
VALKEY_HOST=localhost
VALKEY_PORT=6379
VALKEY_DB=0

# Logging Configuration
LOG_LEVEL=INFO  # Options: DEBUG, INFO, WARNING, ERROR, CRITICAL
```

### Getting API Keys

#### OpenAI API Key
1. Visit https://platform.openai.com/api-keys
2. Sign in to your OpenAI account (create one if needed)
3. Click "Create new secret key"
4. Copy the generated key to your `.env` file
5. Note: Your key will start with `sk-proj-` (DO NOT commit this to git)

## ğŸ“š Supported Models

### Currently Implemented

| Model Name | Provider | Model ID | Status | Best For |
|-----------|----------|----------|--------|----------|
| **Owl (Primary)** | OpenAI | `gpt-5` | Active | Clinical specialization, optimal quality |
| **Falcon (Fallback)** | OpenAI | `gpt-4o` | Active | Reliable fallback, cost-efficient |

### Model Specifications

**GPT-5 OWL:**
- Input tokens: $0.015/1K tokens
- Output tokens: $0.060/1K tokens
- Context window: 128K tokens
- Max output: 8,192 tokens
- Best for: Clinical protocols, regulatory documents

**GPT-4o Falcon:**
- Input tokens: $0.005/1K tokens
- Output tokens: $0.015/1K tokens
- Context window: 128K tokens
- Max output: 4,096 tokens
- Best for: General documents, cost optimization

### Model Selection & Fallback

The system automatically:
1. Attempts translation with GPT-5 OWL (primary model)
2. Falls back to GPT-4o if OWL fails
3. Logs all fallback events with reasons

## ğŸ—ï¸ Project Structure

```
transai/
â”œâ”€â”€ src/                                    # Core application code
â”‚   â”œâ”€â”€ production_pipeline_*.py            # Main translation pipelines
â”‚   â”‚   â”œâ”€â”€ production_pipeline_batch_enhanced.py      # RECOMMENDED - General purpose
â”‚   â”‚   â”œâ”€â”€ production_pipeline_en_ko.py               # ENâ†’KO clinical specialization
â”‚   â”‚   â”œâ”€â”€ production_pipeline_ko_en_improved.py      # KOâ†’EN with tag preservation
â”‚   â”‚   â””â”€â”€ production_pipeline_with_style_guide.py    # Style guide variants
â”‚   â”œâ”€â”€ glossary/                          # Glossary management
â”‚   â”‚   â”œâ”€â”€ glossary_loader.py             # Load glossary files
â”‚   â”‚   â”œâ”€â”€ glossary_search.py             # Fuzzy term matching
â”‚   â”‚   â””â”€â”€ create_combined_glossary.py    # Glossary creation
â”‚   â”œâ”€â”€ style_guide_config.py              # 10 translation style variants
â”‚   â”œâ”€â”€ memory/                            # Caching layer (3-tier architecture)
â”‚   â”‚   â”œâ”€â”€ valkey_manager.py              # Valkey/Redis integration
â”‚   â”‚   â”œâ”€â”€ session_manager.py             # Session tracking & progress
â”‚   â”‚   â”œâ”€â”€ consistency_tracker.py         # Term consistency maintenance
â”‚   â”‚   â””â”€â”€ cached_glossary_search.py      # Cached glossary lookups
â”‚   â”œâ”€â”€ utils/                             # Utilities
â”‚   â”‚   â”œâ”€â”€ tag_handler.py                 # CAT tool tag preservation
â”‚   â”‚   â””â”€â”€ segment_filter.py              # Content filtering
â”‚   â”œâ”€â”€ clinical_protocol_system/          # Medical specialization
â”‚   â”‚   â”œâ”€â”€ extract_protocol_terms.py      # Protocol term extraction
â”‚   â”‚   â”œâ”€â”€ agents/                        # AI agent configurations
â”‚   â”‚   â”œâ”€â”€ templates/                     # Prompt templates
â”‚   â”‚   â””â”€â”€ data/                          # Protocol terminology
â”‚   â”œâ”€â”€ tests/                             # Unit and integration tests
â”‚   â”œâ”€â”€ data/                              # Glossaries and test data
â”‚   â”‚   â”œâ”€â”€ production_glossary.json       # Full glossary (503KB)
â”‚   â”‚   â”œâ”€â”€ production_glossary.xlsx       # Excel format (155KB)
â”‚   â”‚   â”œâ”€â”€ combined_en_ko_glossary.xlsx   # Clinical terminology (20KB)
â”‚   â”‚   â”œâ”€â”€ sample_glossary.json           # Example format
â”‚   â”‚   â””â”€â”€ sample_test_data.json          # Test segments
â”‚   â”œâ”€â”€ analysis/                          # Analysis tools
â”‚   â”œâ”€â”€ evaluation/                        # Evaluation metrics
â”‚   â”œâ”€â”€ results/                           # Execution results
â”‚   â”œâ”€â”€ config/                            # Configuration files
â”‚   â”œâ”€â”€ logs/                              # Application logs
â”‚   â”œâ”€â”€ requirements.txt                   # Python dependencies
â”‚   â”œâ”€â”€ .env                               # Configuration (DO NOT COMMIT)
â”‚   â””â”€â”€ README.md                          # Src directory documentation
â”‚
â”œâ”€â”€ docs/                                  # Technical documentation
â”‚   â”œâ”€â”€ README.md                          # This file (navigation & quick start)
â”‚   â””â”€â”€ [See Documentation Index below]
â”‚
â””â”€â”€ README.md                              # Root project README
```

## ğŸ”„ Translation Pipelines

### 1. Batch Enhanced Pipeline (RECOMMENDED)

**File:** `src/production_pipeline_batch_enhanced.py`

Best for production use with optimal performance:

```python
from src.production_pipeline_batch_enhanced import EnhancedBatchPipeline

pipeline = EnhancedBatchPipeline(
    style_guide="STANDARD",
    batch_size=5,
    model_name="Owl"
)

results = pipeline.translate(input_file="input.xlsx")
```

**Performance:**
- 2.5 seconds per 5-segment batch
- Quality score: 0.84 average (0.74-0.98 range)
- Token reduction: 98.3%

### 2. Clinical Protocol Pipeline (ENâ†’KO)

**File:** `src/production_pipeline_en_ko.py`

Specialized for English-to-Korean clinical protocols:

```python
from src.production_pipeline_en_ko import EnKoClinicialPipeline

pipeline = EnKoClinicialPipeline()
results = pipeline.translate(input_file="protocol.xlsx")
```

**Features:**
- Combined glossary (419 clinical terms)
- Regulatory compliance style guide
- Bilingual terminology formatting

### 3. KO-EN Improved Pipeline

**File:** `src/production_pipeline_ko_en_improved.py`

For Korean-to-English translation with tag preservation:

```python
from src.production_pipeline_ko_en_improved import KoEnImprovedPipeline

pipeline = KoEnImprovedPipeline()
results = pipeline.translate(input_file="document.xlsx")
```

**Features:**
- CAT tool tag preservation
- Glossary term consistency
- Hallucination detection

## ğŸ“– Usage Examples

### Basic Translation

```python
import os
from dotenv import load_dotenv
from src.production_pipeline_batch_enhanced import EnhancedBatchPipeline

# Load environment variables
load_dotenv()

# Create pipeline
pipeline = EnhancedBatchPipeline(
    style_guide="STANDARD",
    batch_size=5
)

# Translate file
results = pipeline.translate(
    input_file="documents/sample.xlsx",
    output_file="documents/sample_translated.xlsx"
)

print(f"Processed {results['total_segments']} segments")
print(f"Average quality score: {results['avg_quality_score']:.2f}")
```

### Using Glossary Terms

```python
from src.glossary_loader import GlossaryLoader
from src.glossary_search import GlossarySearchEngine

# Load glossary
loader = GlossaryLoader()
glossary = loader.load_combined_glossary("data/sample_glossary.json")

# Search for terms
search_engine = GlossarySearchEngine(glossary)
results = search_engine.search("ì„ìƒì‹œí—˜", top_k=5)

for match in results:
    print(f"{match['korean']} â†’ {match['english']} ({match['score']})")
```

### Custom Style Guide

```python
from src.style_guide_config import StyleGuideManager
from src.production_pipeline_batch_enhanced import EnhancedBatchPipeline

# Configure style guide
style_manager = StyleGuideManager()
pipeline = EnhancedBatchPipeline(
    style_guide="COMPREHENSIVE",  # More tokens, higher quality
    style_guide_variant="REGULATORY_COMPLIANCE"
)

results = pipeline.translate(input_file="regulatory_docs.xlsx")
```

## ğŸ”‘ Glossary Format

The system supports glossary files in JSON format. See `data/sample_glossary.json` for a complete example.

### JSON Structure

```json
{
  "glossary_metadata": {
    "version": "1.0",
    "language_pair": "ko-en",
    "created_date": "2025-11-23",
    "description": "Sample medical terminology glossary"
  },
  "terms": [
    {
      "korean": "ì„ìƒì‹œí—˜",
      "english": "clinical trial",
      "category": "clinical",
      "context": "Medical context or usage example",
      "frequency": "high"
    }
  ],
  "abbreviations": [
    {
      "korean": "ICH",
      "english": "International Council for Harmonisation",
      "context": "Regulatory standards"
    }
  ]
}
```

### Adding Your Own Glossary

1. **Create a JSON file** in `data/` directory following the format above
2. **Update the pipeline** to load your glossary:

```python
loader = GlossaryLoader()
custom_glossary = loader.load_custom_glossary("data/your_glossary.json")

pipeline = EnhancedBatchPipeline(glossary=custom_glossary)
```

## ğŸ“Š Style Guides

The system provides 10 configurable style guide variants optimized for different scenarios:

| Variant | Tokens | Best For | Quality vs Speed |
|---------|--------|----------|-----------------|
| NONE | 0 | Baseline | Fastest |
| MINIMAL | 100 | Quick translations | Fast |
| COMPACT | 200 | Standard documents | Balanced |
| STANDARD | 400 | Most use cases | Balanced |
| COMPREHENSIVE | 600 | Complex documents | Quality |
| CLINICAL_PROTOCOL | 300 | ENâ†’KO clinical | Specialized |
| REGULATORY_COMPLIANCE | 300 | KOâ†’EN regulatory | Specialized |
| REGULATORY_COMPLIANCE_ENHANCED | 900 | Critical regulatory | Highest quality |

### Setting Style Guide

```python
pipeline = EnhancedBatchPipeline(style_guide="COMPREHENSIVE")
```

## ğŸ§  Memory System (Caching)

The system uses a 3-tier memory architecture for optimal performance:

### Tier 1: Valkey/Redis Cache
- Sub-millisecond O(1) lookups
- Glossary term caching
- Session management
- Connection pooling (20 connections)

### Tier 2: Session Memory
- Document-level tracking
- Term consistency across segments
- Progress tracking

### Tier 3: Style Guide Management
- Pre-computed style variants
- A/B testing framework

### Using the Memory System

```python
from src.memory.valkey_manager import ValkeyManager
from src.memory.session_manager import SessionManager

# Initialize managers
valkey_mgr = ValkeyManager(host="localhost", port=6379)
session_mgr = SessionManager(valkey_mgr)

# Create document session
session_id = session_mgr.create_session(
    document_name="clinical_protocol.pdf",
    total_segments=100
)

# Track progress
session_mgr.update_progress(session_id, segments_completed=50)

# Retrieve session status
status = session_mgr.get_session_status(session_id)
```

## ğŸ·ï¸ CAT Tool Tag Preservation

The system preserves special tags used by Computer-Aided Translation tools:

### Supported Tag Types

- **Self-closing:** `<123/>`
- **Opening tags:** `<123>`
- **Closing tags:** `</123>`
- **Paired tags:** `<123>text</123>`
- **Metadata:** `[IN_ECN_301]`

### Using Tag Handler

```python
from src.utils.tag_handler import TagHandler

handler = TagHandler()

# Extract tags
text = "This is <1>important</1> clinical data <2/>."
tags = handler.extract_tags(text)
clean_text = handler.remove_tags(text)

# Restore tags after translation
translated_clean = "Ceci est <1>important</1> donnÃ©es cliniques <2/>."
restored = handler.restore_tags(translated_clean, tags)
```

## ğŸ“ˆ Performance Metrics

### Translation Performance

```
Token Reduction:      98.3% (20,473 â†’ 413 tokens)
Processing Speed:     720 words/minute
Batch Processing:     2.5 seconds per 5 segments
Quality Score:        0.84 average (0.74-0.98 range)
Cache Lookup:         <1ms (O(1) operations)
```

### Cost per Segment

- **Average cost:** ~$0.006 per segment (using GPT-5 OWL)
- **Glossary coverage:** 89.6% of medical terms
- **Fallback rate:** <2% (automatic GPT-4o fallback)

## ğŸ§ª Testing

### Run Unit Tests

```bash
# Run all tests
pytest tests/

# Run specific test file
pytest tests/test_glossary_loader.py -v

# Run with coverage
pytest --cov=src tests/
```

### Sample Test Data

The project includes sample test data in `data/sample_test_data.json`:

- 15 synthetic translation segments
- Mix of KOâ†’EN and ENâ†’KO directions
- Multiple difficulty levels (easy, medium)
- Various medical categories (regulatory, clinical, device, operational)

## ğŸ› Troubleshooting

### Common Issues

#### 1. "ModuleNotFoundError: No module named 'openai'"

**Solution:**
```bash
pip install --upgrade openai>=1.51.2
```

#### 2. "Connection refused: Cannot connect to Valkey"

**Solution:**
```bash
# Check Valkey is running
valkey-cli ping  # Should return "PONG"

# If not running, start it:
valkey-server  # Or use Docker: docker run -d -p 6379:6379 valkey/valkey
```

#### 3. "Invalid API key" error

**Solution:**
- Verify your OpenAI API key in `.env` file
- Check that key starts with `sk-proj-`
- Ensure no extra spaces or quotes around the key
- Test key at https://platform.openai.com/account/api-keys

#### 4. "GPT-5 OWL failed, using GPT-4o fallback"

This is normal behavior. The system automatically falls back to GPT-4o if GPT-5 fails. You can:
- Check logs for the specific failure reason
- Set `LOG_LEVEL=DEBUG` for detailed information
- Review API rate limits on OpenAI dashboard

## ğŸ“š Find Specific Topics

Documentation is organized by category. Use these links to jump to what you need:

| Need Help With... | Go To... |
|---|---|
| Getting started | [01_getting_started/INDEX.md](01_getting_started/INDEX.md) |
| Understanding architecture | [02_architecture/INDEX.md](02_architecture/INDEX.md) |
| Using translation features | [03_core_features/INDEX.md](03_core_features/INDEX.md) |
| Managing glossaries | [04_glossary_and_terminology/INDEX.md](04_glossary_and_terminology/INDEX.md) |
| Advanced optimization | [05_advanced_topics/INDEX.md](05_advanced_topics/INDEX.md) |
| Performance & testing | [06_performance_and_optimization/INDEX.md](06_performance_and_optimization/INDEX.md) |
| Project & security | [07_project_management/INDEX.md](07_project_management/INDEX.md) |

**Each category has an INDEX.md file that navigates the documents in that section.**

## ğŸ”§ Development

### Project Dependencies

Core dependencies are listed in `requirements.txt`. Key packages:

- **LLM Integration:** `openai>=1.51.2`
- **Caching:** `valkey>=6.1.1`
- **Data Processing:** `pandas>=2.0.0`, `openpyxl>=3.1.0`
- **Async:** `asyncio`, `aiohttp`
- **Config:** `python-dotenv>=1.0.0`
- **Testing:** `pytest`, `pytest-asyncio`, `pytest-mock`

### Adding New Features

1. Create feature branch: `git checkout -b feature/description`
2. Implement changes following existing code style
3. Add unit tests in `tests/`
4. Update documentation in `docs/`
5. Test with sample data in `data/sample_test_data.json`

## ğŸ“ License

[Add your license information here]

## ğŸ“§ Support

For questions or issues:
1. Check existing documentation in `docs/`
2. Review sample code in `src/` with inline comments
3. Check test files for usage examples

## âœ¨ Key Features Summary

âœ… **98.3% token reduction** through intelligent context optimization
âœ… **Clinical specialization** with medical device/trial terminology
âœ… **Fast processing** - 720 words/minute (10x human speed)
âœ… **High quality** - 84% average quality score
âœ… **Smart caching** - Sub-millisecond Valkey integration
âœ… **CAT integration** - Tag preservation for workflow tools
âœ… **Flexible styling** - 10 style guide variants
âœ… **Auto fallback** - Graceful degradation to GPT-4o
âœ… **Production ready** - Comprehensive error handling and logging

---

**Version:** 1.0.0
**Last Updated:** November 23, 2025
**Status:** Production Ready
