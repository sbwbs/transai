#!/usr/bin/env python3
"""
Create Combined Glossary for EN-KO Translation
Combines glossaries from all available sources into a single standardized file
"""

import pandas as pd
import os
from datetime import datetime

def create_combined_glossary():
    """Create combined glossary from all available sources"""
    
    combined_terms = []
    total_processed = 0
    
    print("ğŸ”„ Creating Combined EN-KO Glossary...")
    print("=" * 60)
    
    # Source 1: GENERIC_CLINIC Glossary (ENâ†’KO)
    print("\nğŸ“š Processing GENERIC_CLINIC Glossary...")
    try:
        generic_provider_file = "../Phase 2_AI testing kit/ì˜í•œ/2_ìš©ì–´ì§‘_GENERIC_CLINIC Glossary.xlsx"
        df_generic_provider = pd.read_excel(generic_provider_file)
        
        generic_provider_added = 0
        for _, row in df_generic_provider.iterrows():
            english = str(row.get('English', '')).strip()
            korean = str(row.get('Korean', '')).strip()
            
            if english and korean:
                combined_terms.append({
                    'English': english,
                    'Korean': korean,
                    'Source': 'GENERIC_CLINIC',
                    'Priority': 1  # High priority - specific to current dataset
                })
                generic_provider_added += 1
        
        print(f"âœ… Added {generic_provider_added} terms from GENERIC_CLINIC")
        total_processed += generic_provider_added
        
    except Exception as e:
        print(f"âŒ Error processing GENERIC_CLINIC: {e}")
    
    # Source 2: Coding Form Glossary (KOâ†’EN reversed to ENâ†’KO)
    print("\nğŸ“š Processing Coding Form Glossary...")
    try:
        coding_file = "../Phase 2_AI testing kit/í•œì˜/2_ìš©ì–´ì§‘_Coding Form.xlsx"
        df_coding = pd.read_excel(coding_file)
        
        coding_added = 0
        for _, row in df_coding.iterrows():
            korean = str(row.get('KR_SOC_27.0', '')).strip()
            english = str(row.get('SOC_27.0', '')).strip()
            
            # Filter for medical terms (remove common words, numbers)
            if (english and korean and 
                len(english) > 3 and len(korean) > 1 and
                not english.replace(' ', '').isdigit() and 
                not korean.replace(' ', '').isdigit() and
                english.lower() not in ['and', 'the', 'of', 'to', 'in', 'a', 'an', 'for', 'with', 'or', 'by'] and
                # Medical/clinical terms
                any(word in english.lower() for word in ['disorder', 'disease', 'syndrome', 'condition', 'adverse', 'event', 'reaction', 'medical', 'clinical', 'therapeutic', 'drug', 'treatment', 'diagnosis', 'symptom'])):
                
                # Check if not already exists (avoid duplicates)
                existing = [t for t in combined_terms if t['English'].lower() == english.lower()]
                if not existing:
                    combined_terms.append({
                        'English': english,
                        'Korean': korean,
                        'Source': 'Coding Form (Medical)',
                        'Priority': 2  # Medium priority - broader medical terms
                    })
                    coding_added += 1
        
        print(f"âœ… Added {coding_added} relevant medical terms from Coding Form")
        total_processed += coding_added
        
    except Exception as e:
        print(f"âŒ Error processing Coding Form: {e}")
    
    # Source 3: Clinical Trials Glossary (KOâ†’EN reversed to ENâ†’KO)  
    print("\nğŸ“š Processing Clinical Trials Glossary...")
    try:
        trials_file = "../Phase 2_AI testing kit/í•œì˜/2_ìš©ì–´ì§‘_SAMPLE_CLIENT KO-EN Clinical Trial Reference_20250421.xlsx"
        df_trials = pd.read_excel(trials_file)
        
        trials_added = 0
        for _, row in df_trials.iterrows():
            korean_raw = str(row.get('KO', '')).strip()
            english_raw = str(row.get('EN', '')).strip()
            
            # Handle multiple terms separated by |
            korean_terms = [k.strip() for k in korean_raw.split('|') if k.strip()]
            english_terms = [e.strip() for e in english_raw.split('|') if e.strip()]
            
            # Use the first/primary term from each
            if korean_terms and english_terms:
                korean = korean_terms[0]
                english = english_terms[0]
                
                # Clean up Korean text (remove parenthetical English if present)
                if '(' in korean and ')' in korean:
                    korean = korean.split('(')[0].strip()
                
                if (english and korean and len(english) > 2 and len(korean) > 1 and
                    not english.replace(' ', '').isdigit()):
                    
                    # Check if not already exists
                    existing = [t for t in combined_terms if t['English'].lower() == english.lower()]
                    if not existing:
                        combined_terms.append({
                            'English': english,
                            'Korean': korean,  
                            'Source': 'Clinical Trials',
                            'Priority': 1  # High priority - clinical trials specific
                        })
                        trials_added += 1
        
        print(f"âœ… Added {trials_added} terms from Clinical Trials")
        total_processed += trials_added
        
    except Exception as e:
        print(f"âŒ Error processing Clinical Trials: {e}")
    
    # Create combined DataFrame
    if combined_terms:
        df_combined = pd.DataFrame(combined_terms)
        
        # Sort by priority (higher first), then by source, then alphabetically
        df_combined = df_combined.sort_values(['Priority', 'Source', 'English'])
        
        # Save to Excel
        output_file = "../data/combined_en_ko_glossary.xlsx"
        os.makedirs(os.path.dirname(output_file), exist_ok=True)
        df_combined.to_excel(output_file, index=False)
        
        print(f"\nğŸ‰ Combined Glossary Created Successfully!")
        print(f"ğŸ“ File: {output_file}")
        print(f"ğŸ“Š Total unique terms: {len(df_combined)}")
        
        # Statistics by source
        print(f"\nğŸ“ˆ Terms by source:")
        source_stats = df_combined['Source'].value_counts()
        for source, count in source_stats.items():
            print(f"   â€¢ {source}: {count} terms")
        
        # Show samples
        print(f"\nğŸ“ Sample terms from combined glossary:")
        for source in df_combined['Source'].unique():
            sample = df_combined[df_combined['Source'] == source].head(3)
            print(f"\n{source}:")
            for _, row in sample.iterrows():
                print(f"   â€¢ {row['English']} â†’ {row['Korean']}")
        
        return output_file, len(df_combined)
    
    else:
        print(f"âŒ No terms could be processed from any source!")
        return None, 0

if __name__ == "__main__":
    output_file, term_count = create_combined_glossary()
    
    if output_file:
        print(f"\nâœ… Success! Created combined glossary with {term_count} terms")
        print(f"ğŸ“ Location: {output_file}")
        print(f"ğŸš€ Ready to use in EN-KO translation pipeline")
    else:
        print(f"âŒ Failed to create combined glossary")