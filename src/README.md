# Phase 2 Source Code - Production Pipeline

## Current Structure (Cleaned and Organized)

### Active Production Files
```
phase2/src/
├── production_pipeline_working.py  # Main production pipeline with batch processing + Valkey
├── glossary_loader.py              # Glossary integration (2906 terms)
├── glossary_search.py              # Glossary search engine
├── memory/                         # Valkey-based memory management
│   ├── valkey_manager.py          # Valkey/Redis integration for term persistence
│   ├── consistency_tracker.py     # Term consistency management
│   ├── cached_glossary_search.py  # Cached glossary searches
│   └── session_manager.py         # Session state management
├── test_valkey_integration.py     # Valkey integration test script
└── __init__.py                     # Package initialization
```

### Archived Files
All experimental, demo, and obsolete code has been moved to the `archive/` directory:

```
archive/
├── demos/                    # All demo and experimental files
│   ├── demo_context_buisample_clientr.py
│   ├── detailed_translation_demo.py
│   ├── gpt5_integration_demo.py
│   ├── phase2_production_demo.py
│   ├── pipeline_demo.py
│   ├── production_demo_simple.py
│   └── translation_demo.py
│
├── old_pipelines/           # Previous pipeline versions
│   ├── production_gpt5_pipeline.py
│   └── production_pipeline_real.py
│
├── unused_services/         # Service files not used in production
│   ├── batch_processor.py
│   ├── context_buisample_clientr.py
│   ├── data_loader_enhanced.py
│   ├── document_processor.py
│   ├── enhanced_translation_service.py
│   ├── glossary_search.py
│   ├── prompt_formatter.py
│   ├── token_optimizer.py
│   ├── memory/              # Memory management modules (future use)
│   └── model_adapters/      # Model adapter pattern (future use)
│
├── utilities/              # Utility and monitoring tools
│   ├── data_integration.py
│   ├── data_validator.py
│   ├── excel_inspector.py
│   ├── gpt5_cost_optimizer.py
│   ├── gpt5_monitor.py
│   ├── performance_analyzer.py
│   └── validate_integration.py
│
└── docs/                   # Implementation documentation
    ├── BE003_IMPLEMENTATION_SUMMARY.md
    ├── INTEGRATION_GUIDE.md
    └── PACKAGE_REORGANIZATION_SUMMARY.md
```

## Production Pipeline Usage

### Setup Valkey (Optional but Recommended)
```bash
# Install Valkey/Redis if not already installed
brew install valkey  # or redis

# Start Valkey server
redis-server  # Valkey is Redis-compatible

# Verify Valkey is running
redis-cli ping
# Should respond: PONG
```

### Run the Production Pipeline
```bash
cd /Users/won.suh/Project/translate-ai/phase2
python src/production_pipeline_working.py

# To run without Valkey (in-memory fallback)
# The pipeline automatically falls back if Valkey is not available
```

### Test Valkey Integration
```bash
cd /Users/won.suh/Project/translate-ai/phase2/src
python test_valkey_integration.py
```

### Key Features of Production Pipeline
- **Valkey Integration**: Persistent term storage with O(1) lookups (Tier 1 Memory)
- **Batch Processing**: 5 segments per API call (80% API reduction)
- **Clinical Trial Specialization**: ICH GCP-compliant prompts
- **Real Glossary Integration**: 2906 terms from Coding Form and Clinical Trials
- **Session Memory**: Term consistency tracking (Valkey-backed or in-memory)
- **Smart Priority System**: Glossary terms override locked terms in conflicts
- **GPT-5 OWL Integration**: With robust response extraction
- **Comprehensive Reporting**: 4-sheet Excel output with glossary details
- **Automatic Fallback**: Seamless in-memory operation if Valkey unavailable

### Recent Performance Metrics (1400 segments)
- **Processing Time**: ~15.5 minutes
- **API Calls**: 280 (vs 1400 individual)
- **Success Rate**: 99.6%
- **Average Cost**: $0.0367 per segment
- **Glossary Coverage**: 5.3 terms per segment
- **Session Learning**: 137 terms locked

## Why This Organization?

1. **Clean Production Code**: Only actively used files remain in the main directory
2. **Historical Preservation**: All experimental work archived for reference
3. **Clear Dependencies**: Production pipeline only depends on glossary_loader.py
4. **Future Ready**: Memory and adapter patterns preserved for Phase 3 implementation
5. **Easy Maintenance**: Single entry point (production_pipeline_working.py)

## Next Steps

For Phase 3 implementation (Qdrant + Mem0 integration):
1. Restore memory/ modules from archive
2. Integrate with production_pipeline_working.py
3. Add vector search capabilities
4. Implement adaptive learning

## Archive Access

To restore any archived file:
```bash
# Example: Restore memory management
cp -r archive/unused_services/memory/ ./

# Example: Review old pipeline implementation
cat archive/old_pipelines/production_pipeline_real.py
```